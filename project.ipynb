{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.model_selection import StratifiedKFold as KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import tree\n",
    "\n",
    "datasetList = ['abalone.data', 'balance-scale.data', 'transfusion.data', 'australian.dat', 'car.data','breast-cancer-wisconsin.data','pop_failures.dat','german.data']\n",
    "const_ks    = [1, 2, 3, 4, 5, 10, 20, 30, 50, 100, 255, 400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abalone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtName      = 'data/' + datasetList[0]\n",
    "dtLabel     = datasetList[0]\n",
    "\n",
    "df          = pd.read_csv(dtName, header=None)\n",
    "X, y        = df.iloc[:,:-1].values, df.iloc[:, -1].values\n",
    "enc         = OneHotEncoder(handle_unknown='ignore')\n",
    "one_hot     = enc.fit_transform(X[:, 0, None])\n",
    "one_hot_arr = one_hot.toarray()\n",
    "X           = normalize(X[:, 1:])\n",
    "X           = np.concatenate((one_hot_arr, X), axis=1)\n",
    "corr_x      = np.corrcoef(X)\n",
    "print(X.shape)\n",
    "print(corr_x)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtName      = 'data/' + datasetList[2]\n",
    "dtLabel     = datasetList[2]\n",
    "\n",
    "df          = pd.read_csv(dtName)\n",
    "X, y        = df.iloc[:,:-1].values, df.iloc[:, -1].values\n",
    "X           = normalize(X)\n",
    "corr_x      = np.corrcoef(X)\n",
    "print(X.shape)\n",
    "print(corr_x)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Australian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtName      = 'data/' + datasetList[3]\n",
    "dtLabel     = datasetList[3]\n",
    "\n",
    "df          = pd.read_csv(dtName, header=None,delim_whitespace=True)\n",
    "X, y        = df.iloc[:,:-1].values, df.iloc[:, -1].values\n",
    "enc         = OneHotEncoder(handle_unknown='ignore')\n",
    "one_hot     = enc.fit_transform(X[:, 0, None])\n",
    "one_hot_arr = one_hot.toarray()\n",
    "X           = normalize(X[:, 1:])\n",
    "X           = np.concatenate((one_hot_arr, X), axis=1)\n",
    "corr_x      = np.corrcoef(X)\n",
    "print(X.shape)\n",
    "print(corr_x)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtName      = 'data/' + datasetList[4]\n",
    "dtLabel     = datasetList[4]\n",
    "df          = pd.read_csv(dtName, header=None)\n",
    "number      = LabelEncoder()\n",
    "\n",
    "for i in range(len(df.columns)):\n",
    "    df[i]   = number.fit_transform(df[i].astype('str'))\n",
    "    \n",
    "X, y        = df.iloc[:,:-1].values, df.iloc[:, -1].values\n",
    "enc         = OneHotEncoder(handle_unknown='ignore')\n",
    "one_hot     = enc.fit_transform(X[:, 0, None])\n",
    "one_hot_arr = one_hot.toarray()\n",
    "X           = normalize(X[:, 1:])\n",
    "X           = np.concatenate((one_hot_arr, X), axis=1)\n",
    "corr_x      = np.corrcoef(X)\n",
    "print(X.shape)\n",
    "print(corr_x)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BreastOri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtName      = 'data/' + datasetList[5]\n",
    "dtLabel     = datasetList[5]\n",
    "\n",
    "df          = pd.read_csv(dtName)\n",
    "X, y        = df.iloc[:,:-1].values, df.iloc[:, -1].values\n",
    "y           = y[ np.all(X != '?', axis = 1)]\n",
    "X           = X[ np.all(X != '?', axis = 1)].astype(np.float)\n",
    "X           = normalize(X)\n",
    "corr_x      = np.corrcoef(X)\n",
    "print(X.shape)\n",
    "print(corr_x)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Climate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtName      = 'data/' + datasetList[6]\n",
    "dtLabel     = datasetList[6]\n",
    "\n",
    "df          = pd.read_csv(dtName,delim_whitespace=True)\n",
    "X, y        = df.iloc[:,:-1].values, df.iloc[:, -1].values\n",
    "X           = normalize(X)\n",
    "corr_x      = np.corrcoef(X)\n",
    "print(X.shape)\n",
    "print(corr_x)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtName      = 'data/' + datasetList[7]\n",
    "dtLabel     = datasetList[7]\n",
    "\n",
    "df          = pd.read_csv(dtName, header=None,delim_whitespace=True)\n",
    "number      = LabelEncoder()\n",
    "\n",
    "for i in range(len(df.columns)):\n",
    "    df[i]   = number.fit_transform(df[i].astype('str'))\n",
    "    \n",
    "X, y        = df.iloc[:,:-1].values, df.iloc[:, -1].values\n",
    "enc         = OneHotEncoder(handle_unknown='ignore')\n",
    "one_hot     = enc.fit_transform(X[:, 0, None])\n",
    "one_hot_arr = one_hot.toarray()\n",
    "X           = normalize(X[:, 1:])\n",
    "X           = np.concatenate((one_hot_arr, X), axis=1)\n",
    "corr_x      = np.corrcoef(X)\n",
    "print(corr_x)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dtLabel.split(\".\")[0])\n",
    "print(\"K, AcurÃ¡cia, Obs.\")\n",
    "for i in range(0, len(const_ks)):\n",
    "    n_splits   = 5\n",
    "    k          = const_ks[i]\n",
    "\n",
    "    acc        = []\n",
    "    acurancias = []\n",
    "    train_time = []\n",
    "    test_time  = []\n",
    "    kf = KFold(n_splits=n_splits, random_state=42, shuffle=True)\n",
    "\n",
    "    for train_index, test_index in (kf.split(X, y)):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        neigh = KNeighborsClassifier(n_neighbors=k)\n",
    "        #neigh = KNN(K=k, ktype=ktype)\n",
    "\n",
    "        #Train\n",
    "        start_time = time.time()\n",
    "        neigh.fit(X_train, y_train)\n",
    "        train_time.append( time.time() - start_time )\n",
    "\n",
    "        #Test\n",
    "        start_time = time.time()\n",
    "        pred = neigh.predict(X_test)\n",
    "        test_time.append( time.time() - start_time )\n",
    "\n",
    "        acc.append( (pred == y_test).sum() / pred.shape[0] )\n",
    "\n",
    "    acc        = np.array(acc)\n",
    "    train_time = np.array(train_time)\n",
    "    test_time  = np.array(test_time)\n",
    "    \n",
    "    print(f\"{k:5}, {acc.mean():0.4f} +/- {acc.std():0.4f}, {train_time.mean():0.4f} +/- {train_time.std():0.4f}, \", end='')\n",
    "    print(f\"{test_time.mean():0.4f} +/- {test_time.std():0.4f}\")\n",
    "    \n",
    "    \n",
    "clf = tree.DecisionTreeClassifier()\n",
    "n_splits   = 5\n",
    "k          = const_ks[i]\n",
    "\n",
    "acc        = []\n",
    "acurancias = []\n",
    "train_time = []\n",
    "test_time  = []\n",
    "kf = KFold(n_splits=n_splits, random_state=42, shuffle=True)\n",
    "th_value = 0.999\n",
    "for train_index, test_index in (kf.split(X, y)):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    corr_x_train    = np.corrcoef(X_train)\n",
    "    corr_y_train    = ( corr_x_train > (corr_x_train.max() * th_value)).sum(axis=0)\n",
    "    clf.fit(X_train, corr_y_train)\n",
    "    corr_y_test     = clf.predict(X_test)\n",
    "    neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "    neigh.fit(X_train, y_train)\n",
    "    train_time.append( time.time() - start_time )\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    sum_acc         = 0\n",
    "    for idx, k in enumerate( np.unique(corr_y_test)):\n",
    "        X_test_k = X_test[ corr_y_test == k]\n",
    "        \n",
    "        neigh.set_params(n_neighbors=k)\n",
    "        \n",
    "        #Test\n",
    "        pred = neigh.predict(X_test_k)\n",
    "        test_time.append( time.time() - start_time )\n",
    "        \n",
    "        sum_acc += (pred == y_test[corr_y_test == k]).sum()\n",
    "        \n",
    "    acc.append( sum_acc / len(corr_y_test))\n",
    "acc        = np.array(acc)\n",
    "train_time = np.array(train_time)\n",
    "test_time  = np.array(test_time)\n",
    "print(f\"KTree, {acc.mean():0.4f} +/- {acc.std():0.4f}, {train_time.mean():0.4f} +/- {train_time.std():0.4f}, \" , end='')\n",
    "print(f\"{test_time.mean():0.4f} +/- {test_time.std():0.4f}, TH: {th_value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
